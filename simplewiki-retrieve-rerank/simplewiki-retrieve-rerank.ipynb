{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirments.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirments.txt\n",
    "gradio\n",
    "qdrant-client\n",
    "sentence-transformers\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirments Are:\n",
      "gradio\n",
      "qdrant-client\n",
      "sentence-transformers\n",
      "tqdm\n",
      "-----\n",
      "Collecting gradio (from -r requirments.txt (line 1))\n",
      "  Downloading gradio-4.22.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting qdrant-client (from -r requirments.txt (line 2))\n",
      "  Downloading qdrant_client-1.8.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sentence-transformers (from -r requirments.txt (line 3))\n",
      "  Downloading sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tqdm (from -r requirments.txt (line 4))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting fastapi (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.13.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading gradio_client-0.13.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (0.27.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (3.8.3)\n",
      "Requirement already satisfied: numpy~=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (10.2.0)\n",
      "Collecting pydantic>=2.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading ruff-0.3.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1))\n",
      "  Downloading typer-0.10.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/codespace/.local/lib/python3.10/site-packages (from gradio->-r requirments.txt (line 1)) (4.10.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio->-r requirments.txt (line 1))\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio->-r requirments.txt (line 1)) (2024.2.0)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio->-r requirments.txt (line 1))\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio>=1.41.0 (from qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from qdrant-client->-r requirments.txt (line 2)) (2.0.7)\n",
      "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers->-r requirments.txt (line 3))\n",
      "  Downloading transformers-4.39.1-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers->-r requirments.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers->-r requirments.txt (line 3)) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers->-r requirments.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/codespace/.local/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirments.txt (line 1)) (4.21.1)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio->-r requirments.txt (line 1))\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting protobuf<5.0dev,>=4.21.6 (from grpcio-tools>=1.41.0->qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client->-r requirments.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (0.14.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.14.0->qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio->-r requirments.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio->-r requirments.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirments.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirments.txt (line 1)) (2024.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio->-r requirments.txt (line 1))\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic>=2.0->gradio->-r requirments.txt (line 1))\n",
      "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (12.3.101)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirments.txt (line 3))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m762.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirments.txt (line 3))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirments.txt (line 3))\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1)) (0.4.6)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich<14.0.0,>=10.11.0 (from typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1))\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio->-r requirments.txt (line 1))\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirments.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirments.txt (line 3)) (3.3.0)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client->-r requirments.txt (line 2))\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirments.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirments.txt (line 1)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirments.txt (line 1)) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirments.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirments.txt (line 1)) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1)) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio->-r requirments.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio->-r requirments.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers->-r requirments.txt (line 3)) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirments.txt (line 1))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading qdrant_client-1.8.0-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-2.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.3.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.10.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=aa5f5c9b9a4c9ce974fd84bb0d2443e79e30b52febf3e2043c07b8d66fe7671b\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, tqdm, toolz, tomlkit, shellingham, semantic-version, safetensors, ruff, regex, python-multipart, pydantic-core, protobuf, portalocker, orjson, mdurl, importlib-resources, hyperframe, hpack, grpcio, click, annotated-types, aiofiles, uvicorn, typer, starlette, pydantic, markdown-it-py, huggingface-hub, h2, grpcio-tools, tokenizers, rich, gradio-client, fastapi, transformers, qdrant-client, altair, sentence-transformers, gradio\n",
      "Successfully installed aiofiles-23.2.1 altair-5.2.0 annotated-types-0.6.0 click-8.1.7 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.22.0 gradio-client-0.13.0 grpcio-1.62.1 grpcio-tools-1.62.1 h2-4.1.0 hpack-4.0.0 huggingface-hub-0.21.4 hyperframe-6.0.1 importlib-resources-6.4.0 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.9.15 portalocker-2.8.2 protobuf-4.25.3 pydantic-2.6.4 pydantic-core-2.16.3 pydub-0.25.1 python-multipart-0.0.9 qdrant-client-1.8.0 regex-2023.12.25 rich-13.7.1 ruff-0.3.4 safetensors-0.4.2 semantic-version-2.10.0 sentence-transformers-2.6.0 shellingham-1.5.4 starlette-0.36.3 tokenizers-0.15.2 tomlkit-0.12.0 toolz-0.12.1 tqdm-4.66.2 transformers-4.39.1 typer-0.10.0 uvicorn-0.29.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!echo \"Requirments Are:\" && cat requirments.txt && echo \"-----\"\n",
    "\n",
    "!pip install -r requirments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50.2M/50.2M [00:01<00:00, 34.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "from download_dataset import get_dataset\n",
    "\n",
    "SIMPLE_WIKI_PATH = 'simplewiki-2020-11-01.jsonl.gz'\n",
    "\n",
    "dataset = get_dataset(SIMPLE_WIKI_PATH)\n",
    "\n",
    "passages = dataset['passages']\n",
    "articles = dataset['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_seq_length': 512,\n",
      " 'sentence_embedding_dimension': 384,\n",
      " 'tokenizer': BertTokenizerFast(name_or_path='sentence-transformers/multi-qa-MiniLM-L6-cos-v1', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}}\n",
      "{'max_length': None,\n",
      " 'tokenizer': BertTokenizerFast(name_or_path='cross-encoder/ms-marco-MiniLM-L-12-v2', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "pprint({\n",
    "    'max_seq_length': encoder.get_max_seq_length(),\n",
    "    'sentence_embedding_dimension': encoder.get_sentence_embedding_dimension(),\n",
    "    'tokenizer': encoder.tokenizer\n",
    "})\n",
    "\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "pprint({\n",
    "    'max_length': cross_encoder.max_length,\n",
    "    'tokenizer': cross_encoder.tokenizer\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "qdrant = QdrantClient(':memory:') # create in-mem instance of vector db\n",
    "# qdrant = QdrantClient(\n",
    "#     url=os.environ['QDRANT_URL'],\n",
    "#     api_key=os.environ['QDRANT_API_KEY'],\n",
    "# )\n",
    "\n",
    "COLLECTION_NAME = 'simplewiki'\n",
    "\n",
    "collections_names = list(map(lambda x: x.name, qdrant.get_collections().collections))\n",
    "assert COLLECTION_NAME in collections_names\n",
    "assert qdrant.get_collection(COLLECTION_NAME).vectors_count == 508000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_simplewiki_index import build_index\n",
    "\n",
    "if COLLECTION_NAME not in collections_names:\n",
    "    build_index(\n",
    "        passages=passages, \n",
    "        batch_size=200,\n",
    "        start_idx=0,\n",
    "        encoder=encoder,\n",
    "        collection_name=COLLECTION_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_helpers import (\n",
    "    retrieve_top_k, \n",
    "    rerank_hits,\n",
    "    fetch_top_article, \n",
    "    fetch_top_article_with_passage_highlighted, \n",
    "    extract_sentence_and_partition,\n",
    "    fetch_top_passage\n",
    ")\n",
    "\n",
    "# query = \"who built the pyramids in egypt?\"\n",
    "query = \"capital of united states\"\n",
    "# query = \"egypt history\"\n",
    "top_k = 10\n",
    "\n",
    "original_hits, _ = retrieve_top_k(query, top_k, vec_db=qdrant, encoder=encoder, collection_name=COLLECTION_NAME)\n",
    "\n",
    "# pprint([h['article_id'] for h in original_hits])\n",
    "# pprint(fetch_top_article(original_hits, articles=articles))\n",
    "# pprint(fetch_article_title_with_order(original_hits, articles=articles))\n",
    "# pprint(fetch_top_article_with_passage_highlighted(original_hits, articles=articles))\n",
    "\n",
    "reranked_hits, _ = rerank_hits(query, original_hits, cross_encoder=cross_encoder, articles=articles)\n",
    "\n",
    "# # pprint([h['article_id'] for h in reranked_hits])\n",
    "# fetch_top_article(reranked_hits, articles=articles)\n",
    "# pprint(fetch_article_title_with_order(reranked_hits, articles=articles))\n",
    "# pprint(fetch_top_article_with_passage_highlighted(reranked_hits, articles=articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://578a2ddd183052e293.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://578a2ddd183052e293.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 233, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n",
      "    response = connection.handle_request(\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api_client.py\", line 101, in send_inner\n",
      "    response = self._client.send(request)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_client.py\", line 1015, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 232, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/gradio/queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/gradio/route_utils.py\", line 258, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/gradio/blocks.py\", line 1710, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/gradio/blocks.py\", line 1250, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/codespace/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/gradio/utils.py\", line 693, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_19177/3870750317.py\", line 10, in process_query\n",
      "    original_hits, retrieval_time = retrieve_top_k(query, RETRIEVAL_TOP_K, vec_db=qdrant, encoder=encoder, collection_name=COLLECTION_NAME)\n",
      "  File \"/workspaces/learn-search-relevance/simplewiki-retrieve-rerank/search_helpers.py\", line 8, in retrieve_top_k\n",
      "    results = vec_db.search(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/qdrant_client.py\", line 336, in search\n",
      "    return self._client.search(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/qdrant_remote.py\", line 497, in search\n",
      "    search_result = self.http.points_api.search_points(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api/points_api.py\", line 1388, in search_points\n",
      "    return self._build_for_search_points(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api/points_api.py\", line 636, in _build_for_search_points\n",
      "    return self.api_client.request(\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api_client.py\", line 74, in request\n",
      "    return self.send(request, type_)\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api_client.py\", line 91, in send\n",
      "    response = self.middleware(request, self.send_inner)\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api_client.py\", line 200, in __call__\n",
      "    return call_next(request)\n",
      "  File \"/home/codespace/.python/current/lib/python3.10/site-packages/qdrant_client/http/api_client.py\", line 103, in send_inner\n",
      "    raise ResponseHandlingException(e)\n",
      "qdrant_client.http.exceptions.ResponseHandlingException: timed out\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "RETRIEVAL_TOP_K = 40\n",
    "DISPLAY_TOP_K = 10\n",
    "\n",
    "\n",
    "def process_query(query):\n",
    "  original_hits, retrieval_time = retrieve_top_k(query, RETRIEVAL_TOP_K, vec_db=qdrant, encoder=encoder, collection_name=COLLECTION_NAME)\n",
    "  reranked_hits, reranking_time = rerank_hits(query, original_hits, cross_encoder=cross_encoder, articles=articles)\n",
    "\n",
    "  reranked_hits = reranked_hits[:DISPLAY_TOP_K]\n",
    "\n",
    "  df = pd.DataFrame(\n",
    "    {\n",
    "      \"Retrieval Order\": [value['retrieval_order'] for value in reranked_hits],\n",
    "      \"Reranking Order\": [value['reranked_order'] for value in reranked_hits],\n",
    "      \"Title\": [value['title'] for value in reranked_hits],\n",
    "      \"Answer\": [value['passage'] for value in reranked_hits],\n",
    "      \"Article Text\": [articles[value['article_id']]['content'] for value in reranked_hits],\n",
    "    }\n",
    "  )\n",
    "\n",
    "  return (\n",
    "    fetch_top_article_with_passage_highlighted(reranked_hits, articles=articles),\n",
    "    df,\n",
    "    {\n",
    "      \"Retrieval Time\": str(round(retrieval_time, 3)) + \" s\",\n",
    "      \"Reranking Time\": str(round(reranking_time, 3)) + \" s\",\n",
    "    }\n",
    "  )\n",
    "\n",
    "\n",
    "def update(selected_index: gr.SelectData, df):\n",
    "  val = df.iloc[selected_index.index[0]]\n",
    "  return extract_sentence_and_partition(val['Article Text'], val['Answer'])\n",
    "\n",
    "\n",
    "with gr.Blocks() as retrieve_rerank_demo:\n",
    "  gr.Markdown(\n",
    "      \"\"\"\n",
    "      # Simple Wikipedia Semantic Search 🔍 Through Retrieval and Reranking\n",
    "      By inputing queries or questions, this space leverages machine learning to surface the most relevant Simple Wikipedia passages and articles, providing most relevant answers out of **{}** passages indexed on Qdrant cloud using binary quantization.\n",
    "      \"\"\".format(qdrant.get_collection(COLLECTION_NAME).vectors_count)\n",
    "  )\n",
    "\n",
    "  with gr.Accordion(\"Click to learn about the retreival process\", open=False):\n",
    "    gr.Markdown(\n",
    "      \"\"\"\n",
    "      ## Features\n",
    "      1. Encode all passages from Simple Wikipedia dataset into embeddings using a pretrained bi-encoder [`multi-qa-MiniLM-L6-cos-v1`](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1) from Sentence Transformers\n",
    "      2. Index the embeddings on `Qdrant` cloud using binary quantization for efficient retrieval, resulting in {} vector embeddings for encoded passages\n",
    "      3. The user enters a search query like a sentence or a questions\n",
    "      4. Encoding the user search query using the bi-encoder model\n",
    "      5. Retrieve the 40 most relevant passages to the input query by sifting through the indexed embeddings in the Qdrant collection and by leveraging binary quantization to boost retrieval speed\n",
    "      6. Rerank search results using a cross-encoder [`ms-marco-MiniLM-L-12-v2`](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-12-v2) to priortize the most contextually relevant passages\n",
    "      7. Show the top article with the answer highlighted in green, the top 10 reranked answers in a DataFrame view, and the processing time required for both retrieval and reranking\n",
    "\n",
    "      \"\"\".format(qdrant.get_collection(COLLECTION_NAME).vectors_count)\n",
    "    )\n",
    "\n",
    "  input_question = gr.Textbox(\n",
    "    label=\"Query for Simple Wikipedia articles\",\n",
    "    placeholder=\"Enter a query to search for relevant texts from Simple Wikipedia\",\n",
    "  )\n",
    "  gr.Examples(\n",
    "    examples=[\n",
    "      [\"capital of united states\"],\n",
    "      [\"pyramids of Egypt\"],\n",
    "      [\"number of countries in Africa\"],\n",
    "      [\"how many people live in alexandria\"],\n",
    "      [\"where is the red sea?\"]\n",
    "    ],\n",
    "    inputs=[input_question]\n",
    "  )\n",
    "  button = gr.Button(\"Search 🔍\")\n",
    "\n",
    "  with gr.Accordion(\"Click to read the top article with answer highlighted\", open=True):\n",
    "    highlighted_article_after_rerank = gr.HighlightedText(\n",
    "      value=[], \n",
    "      label=\"Top Article with Answer Highlighted\", \n",
    "      color_map={'relevant passage': 'green'}\n",
    "    )\n",
    "\n",
    "  df_output = gr.Dataframe(\n",
    "    headers=[\n",
    "      \"Retrieval Order\",\n",
    "      \"Reranking Order\",\n",
    "      \"Title\",\n",
    "      \"Answer\",\n",
    "      \"Article Text\"\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  runtime_info = gr.Json()\n",
    "\n",
    "  button.click(\n",
    "    fn=process_query,\n",
    "    inputs=[\n",
    "      input_question,\n",
    "    ],\n",
    "    outputs=[\n",
    "      highlighted_article_after_rerank,\n",
    "      df_output,\n",
    "      runtime_info\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  df_output.select(\n",
    "    fn=update,\n",
    "    inputs=df_output, \n",
    "    outputs=highlighted_article_after_rerank\n",
    "  )\n",
    "\n",
    "\n",
    "retrieve_rerank_demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
